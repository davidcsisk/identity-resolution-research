{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3433513",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install dedupe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bcf0e066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original rows: 200\n",
      "\n",
      "Found 100 groups with multiple records for same true_id\n",
      "\n",
      "First 10 duplicate groups:\n",
      "\n",
      "Cluster 1 - true_id: id-0080 (2 records):\n",
      "  - row_id: row-0002, name: Chavez, Leah, email: lchavez@mail.example.org, phone: (555) 010.0080\n",
      "  - row_id: row-0224, name: Laeh Chavez, email: leah.chavez2@example.net, phone: 555-010-0080\n",
      "\n",
      "Cluster 2 - true_id: id-0013 (2 records):\n",
      "  - row_id: row-0003, name: James Harris, email: nan, phone: (555) 010-0013\n",
      "  - row_id: row-0190, name: Jmaes Harris, email: james.harris5@example.net, phone: 555-010-0013\n",
      "\n",
      "Cluster 3 - true_id: id-0030 (2 records):\n",
      "  - row_id: row-0004, name: Lopez, Levi, email: llopez@mail.example.org, phone: (555) 010.0030\n",
      "  - row_id: row-0154, name: Lvei Lopez, email: levi.lopez1@example.net, phone: 555-010-0030\n",
      "\n",
      "Cluster 4 - true_id: id-0011 (2 records):\n",
      "  - row_id: row-0005, name: Jackson, Henry, email: hjackson@mail.example.org, phone: (555) 010.0011\n",
      "  - row_id: row-0087, name: Henry Jackson, email: nan, phone: (555) 010-0011\n",
      "\n",
      "Cluster 5 - true_id: id-0041 (2 records):\n",
      "  - row_id: row-0008, name: Rayn Roberts, email: ryan.roberts5@example.net, phone: 555-010-0041\n",
      "  - row_id: row-0121, name: Roberts, Ryan, email: rroberts@mail.example.org, phone: (555) 010.0041\n",
      "\n",
      "Cluster 6 - true_id: id-0007 (2 records):\n",
      "  - row_id: row-0009, name: Isabella Moore, email: nan, phone: (555) 010-0007\n",
      "  - row_id: row-0226, name: Iasbella Moore, email: isabella.moore6@example.net, phone: 555-010-0007\n",
      "\n",
      "Cluster 7 - true_id: id-0076 (2 records):\n",
      "  - row_id: row-0010, name: Zeo Marshall, email: zoe.marshall5@example.net, phone: nan\n",
      "  - row_id: row-0113, name: Zoe Marshall, email: nan, phone: (555) 010-0076\n",
      "\n",
      "Cluster 8 - true_id: id-0099 (2 records):\n",
      "  - row_id: row-0012, name: Danielle Harvey, email: nan, phone: nan\n",
      "  - row_id: row-0240, name: Dnaielle Harvey, email: danielle.harvey0@example.net, phone: 555-010-0099\n",
      "\n",
      "Cluster 9 - true_id: id-0035 (2 records):\n",
      "  - row_id: row-0013, name: Carter Baker, email: nan, phone: (555) 010-0035\n",
      "  - row_id: row-0203, name: Crater Baker, email: carter.baker6@example.net, phone: 555-010-0035\n",
      "\n",
      "Cluster 10 - true_id: id-0069 (2 records):\n",
      "  - row_id: row-0015, name: Parker Fisher, email: nan, phone: nan\n",
      "  - row_id: row-0028, name: Fisher, Parker, email: pfisher@mail.example.org, phone: (555) 010.0069\n"
     ]
    }
   ],
   "source": [
    "# Using true_id...works fine as expected\n",
    "import pandas as pd\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(r'c:\\Users\\Dave Sisk\\Repos\\soft-relate-data\\sample-data-messy_200.csv')\n",
    "\n",
    "print(f\"Original rows: {len(df)}\")\n",
    "\n",
    "# Function to calculate similarity between two strings\n",
    "def string_similarity(a, b):\n",
    "    if pd.isna(a) or pd.isna(b):\n",
    "        return 0\n",
    "    return SequenceMatcher(None, str(a).lower().strip(), str(b).lower().strip()).ratio()\n",
    "\n",
    "# Find potential duplicates by comparing names within each true_id group\n",
    "duplicate_clusters = []\n",
    "\n",
    "for true_id in df['true_id'].unique():\n",
    "    group = df[df['true_id'] == true_id].copy()\n",
    "    if len(group) > 1:\n",
    "        # Compare names within this true_id group\n",
    "        cluster = {\n",
    "            'true_id': true_id,\n",
    "            'count': len(group),\n",
    "            'records': []\n",
    "        }\n",
    "        for idx, row in group.iterrows():\n",
    "            cluster['records'].append({\n",
    "                'row_id': row['row_id'],\n",
    "                'name': row['name'],\n",
    "                'email': row['email'],\n",
    "                'phone': row['phone']\n",
    "            })\n",
    "        duplicate_clusters.append(cluster)\n",
    "\n",
    "print(f\"\\nFound {len(duplicate_clusters)} groups with multiple records for same true_id\")\n",
    "print(\"\\nFirst 10 duplicate groups:\")\n",
    "\n",
    "for i, cluster in enumerate(duplicate_clusters[:10]):\n",
    "    print(f\"\\nCluster {i+1} - true_id: {cluster['true_id']} ({cluster['count']} records):\")\n",
    "    for record in cluster['records']:\n",
    "        print(f\"  - row_id: {record['row_id']}, name: {record['name']}, email: {record['email']}, phone: {record['phone']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31976279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original rows: 200\n",
      "\n",
      "Found 0 clusters of potential duplicates (not using true_id)\n",
      "\n",
      "First 10 duplicate clusters:\n"
     ]
    }
   ],
   "source": [
    "# true_id hidden from the dedupe process\n",
    "import pandas as pd\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv(r'c:\\Users\\Dave Sisk\\Repos\\soft-relate-data\\sample-data-messy_200.csv')\n",
    "\n",
    "print(f\"Original rows: {len(df)}\")\n",
    "\n",
    "def string_similarity(a, b):\n",
    "    if pd.isna(a) or pd.isna(b):\n",
    "        return 0\n",
    "    return SequenceMatcher(None, str(a).lower().strip(), str(b).lower().strip()).ratio()\n",
    "\n",
    "# Find potential duplicates by comparing names, emails, and phones (but NOT true_id)\n",
    "duplicate_clusters = []\n",
    "\n",
    "# We'll use a simple pairwise comparison for demonstration (O(n^2) for small datasets)\n",
    "used = set()\n",
    "for i, row1 in df.iterrows():\n",
    "    if i in used:\n",
    "        continue\n",
    "    cluster = [row1]\n",
    "    for j, row2 in df.iterrows():\n",
    "        if i != j and j not in used:\n",
    "            # Compare name, email, and phone for similarity\n",
    "            name_sim = string_similarity(row1['name'], row2['name'])\n",
    "            email_sim = string_similarity(row1['email'], row2['email'])\n",
    "            phone_sim = string_similarity(row1['phone'], row2['phone'])\n",
    "            # If any two fields are highly similar, consider as duplicate\n",
    "            if (name_sim > 0.95 and email_sim > 0.95) or (name_sim > 0.95 and phone_sim > 0.95) or (email_sim > 0.95 and phone_sim > 0.95):\n",
    "                cluster.append(row2)\n",
    "                used.add(j)\n",
    "    if len(cluster) > 1:\n",
    "        duplicate_clusters.append(cluster)\n",
    "        for r in cluster:\n",
    "            used.add(r.name)\n",
    "\n",
    "print(f\"\\nFound {len(duplicate_clusters)} clusters of potential duplicates (not using true_id)\")\n",
    "print(\"\\nFirst 10 duplicate clusters:\")\n",
    "\n",
    "for i, cluster in enumerate(duplicate_clusters[:10]):\n",
    "    print(f\"\\nCluster {i+1} with {len(cluster)} records:\")\n",
    "    for record in cluster:\n",
    "        print(f\"  - row_id: {record['row_id']}, name: {record['name']}, email: {record['email']}, phone: {record['phone']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5d73a4fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:dedupe.training:Final predicate set:\n",
      "INFO:dedupe.training:SimplePredicate: (wholeFieldPredicate, name)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dedupe encountered an error: Found array with 0 sample(s) (shape=(0,)) while a minimum of 1 is required.\n",
      "This may be due to insufficient data variation or imbalanced records.\n",
      "Skipping dedupe and returning original filtered dataset.\n",
      "Total records available: 200\n"
     ]
    }
   ],
   "source": [
    "import dedupe\n",
    "\n",
    "# Enhanced duplicate detection with more aggressive matching\n",
    "# while still hiding true_id from dedupe\n",
    "\n",
    "# Fill NaN values with empty strings to avoid AttributeError\n",
    "for col in ['name', 'email', 'phone', 'address']:\n",
    "    df[col] = df[col].fillna('')\n",
    "\n",
    "# Replace empty strings with a placeholder to avoid dedupe errors\n",
    "for col in ['name', 'email', 'phone', 'address']:\n",
    "    df[col] = df[col].replace('', '[BLANK]')\n",
    "\n",
    "# Remove records where all dedupe fields are blank\n",
    "mask = ~((df['name'] == '[BLANK]') & (df['email'] == '[BLANK]') & (df['phone'] == '[BLANK]') & (df['address'] == '[BLANK]'))\n",
    "df_filtered = df[mask].copy()\n",
    "\n",
    "# Convert dataframe to list of dicts for dedupe, excluding true_id\n",
    "records_for_dedupe = df_filtered[['row_id', 'name', 'email', 'phone', 'address']].to_dict('records')\n",
    "\n",
    "# Dedupe requires at least 2 records and at least 2 unique records for training\n",
    "if len(records_for_dedupe) < 2:\n",
    "    print(\"Not enough records to deduplicate after filtering. Skipping dedupe.\")\n",
    "else:\n",
    "    unique_records = [tuple(rec.values()) for rec in records_for_dedupe]\n",
    "    if len(set(unique_records)) < 2:\n",
    "        print(\"All records are identical after filtering. Skipping dedupe.\")\n",
    "    else:\n",
    "        # Prepare data for dedupe, excluding true_id\n",
    "        fields_for_dedupe = [\n",
    "            dedupe.variables.String('name'),\n",
    "            dedupe.variables.String('email'),\n",
    "            dedupe.variables.String('phone'),\n",
    "            dedupe.variables.String('address')\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            # Create dedupe object with more lenient thresholds\n",
    "            deduper = dedupe.Dedupe(fields_for_dedupe)\n",
    "\n",
    "            # Sample for training (use a sample to speed up)\n",
    "            deduper.prepare_training({i: rec for i, rec in enumerate(records_for_dedupe)})\n",
    "            deduper.train({i: rec for i, rec in enumerate(records_for_dedupe)})\n",
    "\n",
    "            # Find matches with lower threshold for more aggressive matching\n",
    "            linked_records = deduper.partition({i: rec for i, rec in enumerate(records_for_dedupe)}, threshold=0.5)\n",
    "\n",
    "            # Print results\n",
    "            print(f\"Found {len(linked_records)} clusters of potential duplicates\")\n",
    "            print(\"\\nFirst 10 duplicate clusters:\")\n",
    "\n",
    "            for i, cluster in enumerate(linked_records[:10]):\n",
    "                print(f\"\\nCluster {i+1} with {len(cluster)} records:\")\n",
    "                for record_id in cluster:\n",
    "                    record = df_filtered.iloc[record_id]\n",
    "                    print(f\"  - row_id: {record['row_id']}, name: {record['name']}, email: {record['email']}, phone: {record['phone']}, true_id: {record['true_id']}\")\n",
    "        except (ValueError, IndexError) as e:\n",
    "            print(f\"Dedupe encountered an error: {str(e)}\")\n",
    "            print(\"This may be due to insufficient data variation or imbalanced records.\")\n",
    "            print(\"Skipping dedupe and returning original filtered dataset.\")\n",
    "            print(f\"Total records available: {len(df_filtered)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
